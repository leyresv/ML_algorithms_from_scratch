{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NaÃ¯ve Bayes algorithm:\n",
        "\n",
        "1.  Create a frequencies dictionnary with:\n",
        "     *  Key: (word, class)\n",
        "     *  Value: the frequency with which that word is mapped to that class in the training set\n",
        "2.  Count the number of positive and negative documents\n",
        "3.  Get the vocabulary size\n",
        "4.  Calculate the log prior\n",
        "5.  Create a dictionary with the log likelihood of each word in the vocabulary\n",
        "6.  Predict the class of a new document by adding the log prior and the log likelihood of each word from the document\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ykrf2YQk5HQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "aFOvp_OUybDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import sentence_polarity, stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download nltk resources\n",
        "nltk.download(\"sentence_polarity\")\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvZQL25jym64",
        "outputId": "ad84a8ee-9e50-42fb-cea4-48462424d005"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package sentence_polarity to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dataset\n",
        "pos_ids = sentence_polarity.fileids('pos')\n",
        "neg_ids = sentence_polarity.fileids('neg')\n",
        "pos_sentences = sentence_polarity.sents(pos_ids)\n",
        "neg_sentences = sentence_polarity.sents(neg_ids)\n",
        "pos_sentences, len(pos_sentences), len(neg_sentences), "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_iKGU_r5haS",
        "outputId": "6ef1bc6a-f648-4a80-fe5d-5fcb4dc316c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', \"century's\", 'new', '\"', 'conan', '\"', 'and', 'that', \"he's\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean-claud', 'van', 'damme', 'or', 'steven', 'segal', '.'], ['the', 'gorgeously', 'elaborate', 'continuation', 'of', '\"', 'the', 'lord', 'of', 'the', 'rings', '\"', 'trilogy', 'is', 'so', 'huge', 'that', 'a', 'column', 'of', 'words', 'cannot', 'adequately', 'describe', 'co-writer/director', 'peter', \"jackson's\", 'expanded', 'vision', 'of', 'j', '.', 'r', '.', 'r', '.', \"tolkien's\", 'middle-earth', '.'], ...],\n",
              " 5331,\n",
              " 5331)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train/test\n",
        "train_pos, train_neg = pos_sentences[:4500], neg_sentences[:4500]\n",
        "test_pos, test_neg = pos_sentences[4500:], neg_sentences[4500:]\n",
        "train_sentences  = train_pos + train_neg\n",
        "test_sentences = test_pos + test_neg\n",
        "len(train_sentences), len(test_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDtT6-uBd2R_",
        "outputId": "12452eb4-e722-4e6f-d980-f70ff125a55a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9000, 1662)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sentiment labels\n",
        "Y_train = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "Y_test = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)\n",
        "Y_train.shape, Y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G908syFNyoso",
        "outputId": "76079fc0-73b5-4a18-d7f2-a00035478fff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9000, 1), (1662, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_sentence(sentence):  \n",
        "    \"\"\"\n",
        "    Remove stopwords, punctuations and lemmatize\n",
        "\n",
        "    :param sentence: Input sentence (String)\n",
        "    :return: tokenized sentence (list)\n",
        "    \"\"\" \n",
        "    stopwords_eng = stopwords.words(\"english\")\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    clean_sentence = [lemmatizer.lemmatize(token) for token in sentence if token not in stopwords_eng and token not in string.punctuation]\n",
        "    return clean_sentence"
      ],
      "metadata": {
        "id": "CXaA5zcpzaqR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_word_freqs_dict(sentences, labels):\n",
        "    \"\"\"\n",
        "    Create frequencies dictionary\n",
        "\n",
        "    :param sentences: list of sentences\n",
        "    :param labels: list of sentences' labels (0 or 1)\n",
        "    :return: vocabulary frequencies dictionary\n",
        "    \"\"\"\n",
        "    tok_sentences = [process_sentence(sentence) for sentence in sentences]\n",
        "    word_freqs = {}\n",
        "    for sentence, label in zip(tok_sentences, labels):\n",
        "        for word in sentence:\n",
        "            if not (word, label[0]) in word_freqs:\n",
        "                word_freqs[(word, label[0])] = 0\n",
        "            word_freqs[(word, label[0])] += 1\n",
        "\n",
        "    sorted_word_freq = sorted(word_freqs.items(), key=lambda x:x[1], reverse=True)\n",
        "    # return dictionary sorted by values \n",
        "    return dict(sorted_word_freq)"
      ],
      "metadata": {
        "id": "ZcgLnJT1zxfn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Likelihood estimation with Laplace smoothing\n",
        "---\n",
        "$$ Likelihood = \\frac{P(Pos)}{P(Neg)}\\prod^m _{i=1} \\frac{P(w_i|Pos)}{P(w_i|Neg)} $$\n",
        "\n",
        "$$ P(w_i | class) = \\frac{freq_{(w_i, class)} + 1}{N_{class} + V}  $$\n",
        "\n",
        "---\n",
        "\n",
        "*  $m$: number of words in the sequence\n",
        "*  $N_{class} $: frequency of all words in a class\n",
        "*  $V$: vocabulary size (number of unique words in the vocabulary)\n",
        "*  Laplace smoothing: we add 1 to the numerator and V to the denominator to avoid multiplying by zero when we find a word that is not in our training vocabulary\n",
        "\n",
        "We get the likelihood score for the sequence:\n",
        "* if score > 1   =>   class 1 (positive)\n",
        "* if score < 1   =>   class 0 (negative)\n",
        "* if score = 1   =>   neutral"
      ],
      "metadata": {
        "id": "XEv-_mXajw6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_conditional_probability(word, label, freqs_dict, n_class, vocab_size):\n",
        "    \"\"\"\n",
        "    Compute the probability of a word given a class: P(word|class)\n",
        "\n",
        "    :param word: string\n",
        "    :param label: class label (0 or 1)\n",
        "    :param freqs_dict: frequencies dictionary\n",
        "    :param n_class: int class frequency\n",
        "    :param vocab_size: int number of words in the vocabulary\n",
        "    :return: conditional probability value (float)\n",
        "    \"\"\"\n",
        "    return (freqs_dict.get((word, label), 0) + 1) / (n_class + vocab_size)"
      ],
      "metadata": {
        "id": "x-YEhywBmDx5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log likelihood\n",
        "\n",
        "To avoid numerical flow issues with the likelihood product, we introduce the log:\n",
        "\n",
        "---\n",
        "$$ Loglikelihood = log\\frac{P(Pos)}{P(Neg)} + \\sum^m _{i=1} \\log\\frac{P(w_i|Pos)}{P(w_i|Neg)} $$\n",
        "\n",
        "---\n",
        "The first component of the equation is the log prior and represents the classes distribution accross the whole training set, that is, the ratio of positive/negative documents in the training set. For perfectly balanced datasets, this ratio will be 1 so its log will be 0 and we won't add anything to the log likelihood.\n",
        "\n",
        "We get the log likelihood score for the sequence:\n",
        " * if score > 0   =>   class 1 (positive)\n",
        " * if score < 0   =>   class 0 (negative)\n",
        " * if score = 0   =>   neutral\n",
        "    \n",
        "Reminder: log properties:\n",
        "   *  $log(xy) = log(x) + log(y)  $\n",
        "   *  $log\\frac{x}{y} = log(x) - log(y)$"
      ],
      "metadata": {
        "id": "-4okABBDnvYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_log_prior(labels):\n",
        "    \"\"\"\n",
        "    Calculate te log prior\n",
        "\n",
        "    :param labels: list of training labels\n",
        "    :return: log prior value (float)\n",
        "    \"\"\"\n",
        "    p_pos = sum(labels)\n",
        "    p_neg = len(labels) - p_pos\n",
        "    return np.log(p_pos) - np.log(p_neg)"
      ],
      "metadata": {
        "id": "cambu_ibaYzV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(x_train, y_train):\n",
        "    \"\"\"\n",
        "    Train the classifier\n",
        "\n",
        "    :param x_train: list of training tokenized sentences (list of lists of strings)\n",
        "    :param y_train: training labels\n",
        "    :return: log prior value, log likelihood dictionary, frequencies dictionary\n",
        "    \"\"\"\n",
        "\n",
        "    freqs_dict = create_word_freqs_dict(x_train, y_train)\n",
        "    log_likelihood = {}\n",
        "\n",
        "    # Get classes frequency\n",
        "    num_pos = np.sum(np.array([freqs_dict[(word, label)] for (word, label) in freqs_dict.keys() if label == 1]))\n",
        "    num_neg = np.sum(np.array([freqs_dict[(word, label)] for (word, label) in freqs_dict.keys() if label == 0]))\n",
        "\n",
        "    # Get vocab size\n",
        "    vocab = set([word for (word, _) in freqs_dict.keys()])\n",
        "    vocab_size = len(vocab)\n",
        "\n",
        "    # Get dataset log prior\n",
        "    log_prior = get_log_prior(y_train)\n",
        "\n",
        "    # Get log likelihood of each word\n",
        "    for word in vocab:\n",
        "        prob_pos = get_conditional_probability(word, 1, freqs_dict, num_pos, vocab_size)\n",
        "        prob_neg = get_conditional_probability(word, 0, freqs_dict, num_neg, vocab_size)\n",
        "        log_likelihood[word] = np.log(prob_pos) - np.log(prob_neg)\n",
        "\n",
        "    return log_prior, log_likelihood, freqs_dict"
      ],
      "metadata": {
        "id": "RF-bEAjkoD2g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_prior, log_likelihood, freqs_dict = train(train_sentences, Y_train)\n",
        "log_prior, len(log_likelihood), len(freqs_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OPJX0LFqYF_",
        "outputId": "5fcadc08-49e4-48c8-d978-974f605c2638"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.]), 17842, 23730)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for pair, freq in list(freqs_dict.items())[:10]:\n",
        "    print(pair, freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g28JIZg4w_RI",
        "outputId": "6463137b-5b91-4b7d-9ce4-fad8f1320dcf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('film', 1.0) 771\n",
            "('movie', 0.0) 728\n",
            "('film', 0.0) 601\n",
            "('movie', 1.0) 528\n",
            "('like', 0.0) 377\n",
            "('one', 0.0) 313\n",
            "('one', 1.0) 307\n",
            "('--', 0.0) 269\n",
            "('--', 1.0) 267\n",
            "('make', 1.0) 252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word, log_lik in list(log_likelihood.items())[:10]:\n",
        "    print(word, log_lik)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2SpSI0_xm6H",
        "outputId": "19eef881-1b50-4bd5-8335-da90a9781c33"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "picture 0.03238838271919864\n",
            "schweig 1.0871980487289168\n",
            "scratching 0.3940508681689714\n",
            "socio-political 0.6817329406207513\n",
            "concludes 0.6817329406207513\n",
            "sneak 0.3940508681689714\n",
            "extensively -0.7045614204991395\n",
            "fluidly 0.6817329406207513\n",
            "elie -0.7045614204991395\n",
            "first-timer -0.011414239939194104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_likelihood[\"love\"], log_likelihood[\"hate\"], log_likelihood[\"terrible\"], log_likelihood[\"amazing\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQpmudW1x3Mo",
        "outputId": "7f699e01-387b-49b6-98db-e1ed6f0195a7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6288904592463718,\n",
              " -0.4969220557208942,\n",
              " -0.630453448345417,\n",
              " 2.1286519235570776)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20 most positive words\n",
        "log_lik_list = sorted(log_likelihood.items(), key=lambda x:x[1], reverse=True)\n",
        "log_lik_list[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fXJVmaf0srH",
        "outputId": "0da9542f-90ed-413e-b637-6acca6fc9778"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('riveting', 2.821799104117023),\n",
              " ('engrossing', 2.7294257839860077),\n",
              " ('lively', 2.6276430896760647),\n",
              " ('polished', 2.6276430896760647),\n",
              " ('vividly', 2.553535117522344),\n",
              " ('heartwarming', 2.553535117522344),\n",
              " ('wonderfully', 2.4734924098488076),\n",
              " ('challenging', 2.4734924098488076),\n",
              " ('resonant', 2.4734924098488076),\n",
              " ('frailty', 2.4734924098488076),\n",
              " ('nuance', 2.4734924098488076),\n",
              " ('startling', 2.3864810328591766),\n",
              " ('culture', 2.3864810328591766),\n",
              " ('richly', 2.3864810328591766),\n",
              " ('russian', 2.3864810328591766),\n",
              " ('tour', 2.3864810328591766),\n",
              " ('spare', 2.3864810328591766),\n",
              " ('detailed', 2.3864810328591766),\n",
              " ('jealousy', 2.3864810328591766),\n",
              " ('refreshing', 2.339961017224285)]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20 most negative words\n",
        "log_lik_list[-20:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cif-Ajl469u",
        "outputId": "378db557-9e6e-4579-9dc8-72100bee7a39"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('pinocchio', -2.4093095127375648),\n",
              " ('tuxedo', -2.4093095127375648),\n",
              " ('unintentional', -2.4093095127375648),\n",
              " ('lousy', -2.4093095127375648),\n",
              " ('generic', -2.4093095127375648),\n",
              " ('offensive', -2.496320889727194),\n",
              " ('incoherent', -2.496320889727194),\n",
              " ('seagal', -2.496320889727194),\n",
              " ('boring', -2.496320889727195),\n",
              " ('pointless', -2.5763635974007304),\n",
              " ('tiresome', -2.5763635974007304),\n",
              " ('plodding', -2.5763635974007304),\n",
              " ('product', -2.5763635974007304),\n",
              " ('disguise', -2.5763635974007304),\n",
              " ('uninspired', -2.5763635974007304),\n",
              " ('bore', -2.7194644410414046),\n",
              " ('poorly', -2.844627583995411),\n",
              " ('badly', -2.9558532191056344),\n",
              " ('unfunny', -3.2695107779606767),\n",
              " ('flat', -3.5079218014056748)]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict and evaluate"
      ],
      "metadata": {
        "id": "yqVoVWLGqa59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sentences, log_prior, log_likelihood):\n",
        "    \"\"\"\n",
        "    Predict polarity labels for the input sequences (0=Negative, 1=Positive)\n",
        "\n",
        "    :param sentences: list of tokenized sentences\n",
        "    :param log_prior: log prior value\n",
        "    :param log_likelihood: log likelihood dictionary\n",
        "    :return: list of predicted polarity labels for the input sentences\n",
        "    \"\"\"\n",
        "    sentences = [process_sentence(sentence) for sentence in sentences]\n",
        "    predictions = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        pred = log_prior + np.sum(np.array([log_likelihood.get(word, 0) for word in sentence]))\n",
        "        if pred > 0:\n",
        "            predictions.append(1)\n",
        "        else:\n",
        "            predictions.append(0)\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "xxJv__JCoNWG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict(test_sentences, log_prior, log_likelihood)\n",
        "y_pred[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c40IoIV8oyDt",
        "outputId": "5a333678-0fde-48d8-be2e-ad6c492c1efc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 1, 0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence, label, pred_label in zip(test_sentences[:5], Y_test[:5], y_pred[:5]):\n",
        "    print(sentence)\n",
        "    print(f\"Predicted label: {pred_label} ------- True label: {label[0]}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX0FM3x1sCeX",
        "outputId": "bb379fa2-a237-4f0d-dee3-c5248171f14e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'good', 'music', 'documentary', ',', 'probably', 'one', 'of', 'the', 'best', 'since', 'the', 'last', 'waltz', '.']\n",
            "Predicted label: 1 ------- True label: 1.0\n",
            "\n",
            "['if', 'the', 'plot', 'seems', 'a', 'bit', 'on', 'the', 'skinny', 'side', ',', \"that's\", 'because', 'panic', 'room', 'is', 'interested', 'in', 'nothing', 'more', 'than', 'sucking', 'you', 'in', 'and', 'making', 'you', 'sweat', '.']\n",
            "Predicted label: 0 ------- True label: 1.0\n",
            "\n",
            "['.', '.', '.', '[the', 'film]', 'works', ',', 'due', 'mostly', 'to', 'the', 'tongue-in-cheek', 'attitude', 'of', 'the', 'screenplay', '.']\n",
            "Predicted label: 1 ------- True label: 1.0\n",
            "\n",
            "['the', 'film', 'becomes', 'an', 'overwhelming', 'pleasure', ',', 'and', 'you', 'find', 'yourself', 'rooting', 'for', \"gai's\", 'character', 'to', 'avoid', 'the', 'fate', 'that', 'has', 'befallen', 'every', 'other', 'carmen', 'before', 'her', '.']\n",
            "Predicted label: 0 ------- True label: 1.0\n",
            "\n",
            "['broomfield', 'has', 'a', 'rather', 'unique', 'approach', 'to', 'documentary', '.', 'he', 'thinks', 'the', 'film', 'is', 'just', 'as', 'much', 'a', 'document', 'about', 'him', 'as', 'it', 'is', 'about', 'the', 'subject', '.']\n",
            "Predicted label: 1 ------- True label: 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy = number of correct predicions / total number of predictions\n",
        "def evaluate_accuracy(Y_gold, Y_pred):\n",
        "    \"\"\"\n",
        "    Evaluate accuracy of the predictions\n",
        "\n",
        "    :param Y_gold: actual labels. Numpy array of size (m, 1) (m=number of labels)\n",
        "    :param Y_pred: predicted labels. Numpy array of size m\n",
        "    :return: accuracy value (int)\n",
        "    \"\"\"\n",
        "    return sum([1 for y_gold, y_pred in zip(Y_gold, Y_pred) if y_gold==y_pred]) / len(Y_pred)"
      ],
      "metadata": {
        "id": "ZkvfzE0pqZyO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_accuracy(Y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyzIwnNxqnB-",
        "outputId": "83dbebbd-dd34-44c7-ed4c-a64b7f64a116"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7617328519855595"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize some test sentences and their classification\n",
        "for sentence, label, pred_label in zip(test_sentences[826:836], Y_test[826:836], y_pred[826:836]):\n",
        "    print(\" \".join(sentence))\n",
        "    print(f\"Predicted label: {pred_label} ------- True label: {int(label[0])}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mYT6cfqS-Fg",
        "outputId": "7185be9f-e881-4295-ec8c-4ff78b44af16"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "both exuberantly romantic and serenely melancholy , what time is it there ? may prove to be [tsai's] masterpiece .\n",
            "Predicted label: 1 ------- True label: 1\n",
            "\n",
            "mazel tov to a film about a family's joyous life acting on the yiddish stage .\n",
            "Predicted label: 1 ------- True label: 1\n",
            "\n",
            "standing in the shadows of motown is the best kind of documentary , one that makes a depleted yesterday feel very much like a brand-new tomorrow .\n",
            "Predicted label: 1 ------- True label: 1\n",
            "\n",
            "it's nice to see piscopo again after all these years , and chaykin and headly are priceless .\n",
            "Predicted label: 1 ------- True label: 1\n",
            "\n",
            "provides a porthole into that noble , trembling incoherence that defines us all .\n",
            "Predicted label: 1 ------- True label: 1\n",
            "\n",
            "the whole mess boils down to a transparently hypocritical work that feels as though it's trying to set the women's liberation movement back 20 years .\n",
            "Predicted label: 0 ------- True label: 0\n",
            "\n",
            "' . . . the cast portrays their cartoon counterparts well . . . but quite frankly , scoob and shag don't eat enough during the film . '\n",
            "Predicted label: 1 ------- True label: 0\n",
            "\n",
            "more of the same old garbage hollywood has been trying to pass off as acceptable teen entertainment for some time now .\n",
            "Predicted label: 0 ------- True label: 0\n",
            "\n",
            "tv skit-com material fervently deposited on the big screen .\n",
            "Predicted label: 0 ------- True label: 0\n",
            "\n",
            "[johnnie to and wai ka fai are] sure to find an enthusiastic audience among american action-adventure buffs , but the film's interests may be too narrow to attract crossover viewers .\n",
            "Predicted label: 1 ------- True label: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Useful functions"
      ],
      "metadata": {
        "id": "sD9CMQTzsgFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ratio(word, freqs_dict):\n",
        "    \"\"\"\n",
        "    Calculate ratio of positive/negative frequency of a word in the training set\n",
        "\n",
        "    :param word: string\n",
        "    :return: ratio (float) (>1: positive, <1: negetive)\n",
        "    \"\"\"\n",
        "    return (freqs_dict.get((word, 1), 0) + 1) / (freqs_dict.get((word, 0), 0) + 1)"
      ],
      "metadata": {
        "id": "yntV45Hqsrx-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ratio(\"movie\", freqs_dict), get_ratio(\"love\", freqs_dict), get_ratio(\"terrible\", freqs_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w1k0mcis6Mk",
        "outputId": "ff907815-6025-4bf2-e648-11d8435ebce7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7256515775034293, 1.8970588235294117, 0.5384615384615384)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words_by_threshold(label, threshold, freqs_dict):\n",
        "    \"\"\"\n",
        "    Get vocabulary words that have a minimum level of positiveness/negativeness\n",
        "\n",
        "    :param label: 1 for positive, 0 for negative\n",
        "    :param threshold: that will be used as the cutoff for including a word in the returned dictionary\n",
        "    :return: dictionary of filtered words (key) and their ratio (value)\n",
        "    \"\"\"\n",
        "    filtered_words = {}\n",
        "    for (word, _) in freqs_dict.keys():\n",
        "        ratio = get_ratio(word, freqs_dict)\n",
        "        if label == 1 and ratio >= threshold:\n",
        "            filtered_words[word] = ratio\n",
        "        elif label == 0 and ratio <= threshold:\n",
        "            filtered_words[word] = ratio\n",
        "    return filtered_words"
      ],
      "metadata": {
        "id": "AFDVfQG8smWz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get words with high positive ratio\n",
        "get_words_by_threshold(1, 10, freqs_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSClAjgNtq-q",
        "outputId": "868fa5aa-4308-4342-8eb9-1fdc09542386"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'culture': 11.0,\n",
              " 'engrossing': 15.5,\n",
              " 'refreshing': 10.5,\n",
              " 'absorbing': 10.0,\n",
              " 'inventive': 10.0,\n",
              " 'riveting': 17.0,\n",
              " 'lively': 14.0,\n",
              " 'polished': 14.0,\n",
              " 'vividly': 13.0,\n",
              " 'heartwarming': 13.0,\n",
              " 'resonant': 12.0,\n",
              " 'frailty': 12.0,\n",
              " 'nuance': 12.0,\n",
              " 'challenging': 12.0,\n",
              " 'wonderfully': 12.0,\n",
              " 'startling': 11.0,\n",
              " 'detailed': 11.0,\n",
              " 'russian': 11.0,\n",
              " 'spare': 11.0,\n",
              " 'jealousy': 11.0,\n",
              " 'tour': 11.0,\n",
              " 'richly': 11.0,\n",
              " 'masterful': 10.0,\n",
              " 'bourne': 10.0,\n",
              " 'uncompromising': 10.0,\n",
              " 'reminder': 10.0,\n",
              " 'deft': 10.0,\n",
              " 'superbly': 10.0}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get words with high negative ratio\n",
        "get_words_by_threshold(0, 0.1, freqs_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgWdNc8at_w3",
        "outputId": "2117f449-b2c2-4e5c-93cd-002ee8520747"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dull': 0.09836065573770492,\n",
              " 'boring': 0.08333333333333333,\n",
              " 'flat': 0.030303030303030304,\n",
              " 'unfunny': 0.038461538461538464,\n",
              " 'generic': 0.09090909090909091,\n",
              " 'mediocre': 0.09523809523809523,\n",
              " 'loud': 0.09523809523809523,\n",
              " 'badly': 0.05263157894736842,\n",
              " 'poorly': 0.058823529411764705,\n",
              " 'bore': 0.06666666666666667,\n",
              " 'product': 0.07692307692307693,\n",
              " 'tiresome': 0.07692307692307693,\n",
              " 'pointless': 0.07692307692307693,\n",
              " 'plodding': 0.07692307692307693,\n",
              " 'uninspired': 0.07692307692307693,\n",
              " 'disguise': 0.07692307692307693,\n",
              " 'incoherent': 0.08333333333333333,\n",
              " 'seagal': 0.08333333333333333,\n",
              " 'offensive': 0.08333333333333333,\n",
              " 'lousy': 0.09090909090909091,\n",
              " 'tuxedo': 0.09090909090909091,\n",
              " 'unintentional': 0.09090909090909091,\n",
              " 'pinocchio': 0.09090909090909091,\n",
              " 'comparison': 0.1,\n",
              " 'pile': 0.1,\n",
              " 'ballistic': 0.1,\n",
              " 'stiff': 0.1,\n",
              " 'missed': 0.1,\n",
              " 'leaden': 0.1,\n",
              " 'plotting': 0.1,\n",
              " 'lifeless': 0.1,\n",
              " 'inane': 0.1,\n",
              " 'soggy': 0.1}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}